\chapter{Literature Survey} \label{lit}

Systematic reviews have many different stages that propose themselves as a candidate for automation. This section is going to look at the techniques that have been applied for some of these stages in previous literature.

\section{Indexing and Querying Medline}

Medline is a large collection of medical literature and data from around the world. Typically each entity will contain a title and an abstract containing some information on the study. Whilest Medline as a whole is very easy to access \cite{medline}, the large size and complexity of the data makes it difficult to retrieve the relevant information.

Being able to create a reliant index of Medline would help with the effectiveness of the queries. As such existing medline indexes and IR systems have been created \cite{nlm}

\section{Stopping Criteria} \label{stops}

Stopping criteria a topic of being able to know when to stop looking at a set of documents. This could be useful in a decision making process. Consider having 100 relevant documents, where each document contains a binary value. If we looked at 1/3 of these documents and saw a trend of positive values, we could use this to infer the reliability of the remaining documents.

Another use of stopping criteria is when filtering through potentially relevant documents. Consider a query that returns 10000 documents, of which only a small sub-set of these are relevant. Reviewers would need to filter through each of these 10000 documents to pull out the relevant ones. Or it could be that the reviewers are happy to hit a 90\% recall of relevant documents, and are happy to miss the remaining 10\% in exchange for time-saved.

Two key methods have been proposed for finding stopping points so far, the target method \cite{Satopa11} and the knee method. \cite{Cormack2016}. Both these methods are discussed below \ref{methods}



\subsection{Evaluation Metrics for Finding Stopping Points} \label{evalsstops}

In order to evaluate the suitability of our stopping method, we can use two evaluation metrics. The recall, which is simply the number of documents returned for a topic. The effort which is the number of documents we had to look at for a topic. 

\begin{equation}
Recall = \frac{R}{|D|}
\end{equation}

Where $R$ is the number of returned documents and $D$ is the set of relevant documents.

\begin{equation}
Effort = \frac{L}{|D|}
\end{equation}

Where $L$ is the number of returned documents looked at.

Naturally we could exclusively optimized each of the parameters by either returning everything in the document collection ($R$ = $|D|$) or by just looking at a single document. ($L$ = 1)

Therefore it becomes difficult for us to evaluate our stopping criteria as we need to consider both of these parameters adjacently.

In response to this we can make use of two more evaluation metrics that tell use  more about the performance of our stopping method \cite{Cormack2016}

\begin{equation}
reliability = P [acceptable(S) == 1]
\end{equation}

reliability is computed over all searches and is read as the probability of the acceptability being 1. Where acceptability is calculated as:

\begin{equation}
  acceptability(S)=\begin{cases}
    1, & \text{$recall(S)>=0.7$}.\\
    0, & \text{$recall(S)<0.7$}.
  \end{cases}
\end{equation}

A stopping point is deemed to be acceptable if 70\% of the relevant documents have been found. As such, the reliability is an average over a search method.


\subsection{Existing Stopping Methods} \label{methods}

The target method is a fairly straight forward approach to establishing a stopping point. It was first proposed by Cormack and Grossman \citep{Cormack2016}.

The target $T$ denotes how many documents we should randomly select from our initial query. A larger value of $T$ will increase the effort required as we are more likely to select a document towards the end of the query set. Documents are looked at until the target point $T$ has been reached.